<!-- =======================================================
ğŸš¨ Real-Time Abandoned Luggage Detection (YOLOv12 + Spatio-Temporal)
======================================================= -->

<div align="center">

# ğŸš¨ Real-Time Abandoned Luggage Detection  
## Dual YOLOv12 Models + Tracking-by-Detection + Spatio-Temporal Reasoning

<p>
  <img alt="Python" src="https://img.shields.io/badge/Python-3.10%2B-blue?logo=python&logoColor=white" />
  <img alt="PyTorch" src="https://img.shields.io/badge/PyTorch-2.x-ee4c2c?logo=pytorch&logoColor=white" />
  <img alt="Ultralytics" src="https://img.shields.io/badge/Ultralytics-YOLOv12-111827?logo=github&logoColor=white" />
  <img alt="OpenCV" src="https://img.shields.io/badge/OpenCV-4.x-5C3EE8?logo=opencv&logoColor=white" />
  <img alt="License" src="https://img.shields.io/badge/License-MIT-green" />
</p>

<p>
A real-time surveillance framework that detects and classifies unattended luggage using specialized object detection models and interpretable spatio-temporal constraints.
</p>

</div>

---

# ğŸ§  System Architecture

<p align="center">
<img width="761" src="https://github.com/user-attachments/assets/beec2c70-dd65-403a-90a1-1b331a8028ab">
</p>

### ğŸ” Overview

Abandoned luggage detection is formulated as a **spatio-temporal reasoning task**, not simply frame-level object detection.

The framework integrates:

- ğŸ§³ **YOLOv12m (custom-trained)** â€” optimized for small and deformable luggage (backpack, bag, trolley)
- ğŸ§ **YOLOv12x** â€” high-recall person detection for crowded scenes
- ğŸ”„ **Custom tracking-by-detection** â€” motion-based geometric association
- ğŸ“ **Distance-based supervision constraint**
- â± **Duration-based abandonment logic**

Unlike appearance-based trackers (e.g., DeepSORT), the system relies on:

- IoU-based matching
- Distance gating
- Constant-velocity prediction
- Track smoothing

This ensures stable identities while maintaining computational efficiency.

### ğŸ¯ Abandonment Condition

A luggage track â„“ is declared **abandoned** if:

- No person p satisfies  
  `||c_â„“ âˆ’ c_p||â‚‚ â‰¤ R`
- For a continuous duration  
  `u(t) â‰¥ T_unattended`

This interpretable formulation prevents false alarms from brief separations or detector noise.

---

# ğŸ–¼ Example Dataset Samples

<p align="center">
<img width="924" src="https://github.com/user-attachments/assets/6b436ba9-0d92-4bc3-b14d-9e35fa155664">
</p>

### ğŸ“¸ Dataset Characteristics

The dataset was constructed from approximately **600 publicly available YouTube surveillance videos**, primarily recorded from fixed or quasi-static viewpoints.

It reflects realistic operational conditions, including:

- ğŸ‘¥ Crowd density variation  
- ğŸŒ— Illumination changes  
- ğŸ§³ Small and medium-scale luggage  
- ğŸ” Partial occlusions  
- âš– Natural class imbalance  
- ğŸ“· Compression artifacts and motion blur  

These characteristics make it representative of real-world public safety deployments.

---

# ğŸ“Š Dataset Summary

## ğŸ” General Information

| Attribute | Value |
|------------|--------|
| ğŸ“¸ Images | **29,053** |
| ğŸ·ï¸ Instances | **130,475** |
| ğŸ§³ Classes | backpack, bag, trolley |
| ğŸ“¦ Format | YOLO (normalized coordinates) |
| ğŸ“œ License | MIT |
| ğŸŒ Hosting | Roboflow Universe |
| ğŸ“Š Model Results | Google Drive (link above) |

The class distribution is naturally imbalanced:

- **Trolley** â‰ˆ 51%  
- **Backpack** â‰ˆ 27%  
- **Bag** â‰ˆ 22%  

The imbalance was intentionally preserved to reflect real surveillance data.

---

# ğŸ“‚ Dataset Split

| Split | Images (%) | Instances (%) | Backpack (%) | Bag (%) | Trolley (%) |
|--------|------------|---------------|--------------|----------|-------------|
| **Train** | 25,302 (87.1%) | 112,214 (86.0%) | 26.8% | 22.2% | 51.0% |
| **Valid** | 2,954 (10.2%) | 14,371 (11.0%) | 26.9% | 20.1% | 53.0% |
| **Test** | 797 (2.7%) | 3,890 (3.0%) | 24.1% | 22.5% | 53.4% |
| **Total** | 29,053 (100%) | 130,475 (100%) | 26.7% | 21.9% | 51.3% |

The training-heavy split ensures strong optimization while maintaining representative validation and test subsets.

---

# ğŸ“ Object Scale Distribution

To analyze scale sensitivity, instances were categorized using normalized area thresholds.

Many luggage objects lie near small-object boundaries, motivating the use of scale-aware training modifications.

## ğŸ”¹ S = 0.001400 (~24Ã—24) | M = 0.022500 (~96Ã—96)

| Group | Total | Small | Medium | Large |
|--------|--------|--------|--------|--------|
| TOTAL | 130,475 | 16,476 (12.6%) | 93,435 (71.6%) | 20,564 (15.8%) |
| backpack | 34,901 | 3,490 (10.0%) | 24,662 (70.7%) | 6,749 (19.3%) |
| bag | 28,628 | 3,632 (12.7%) | 19,136 (66.8%) | 5,860 (20.5%) |
| trolley | 66,946 | 9,354 (14.0%) | 49,637 (74.1%) | 7,955 (11.9%) |

Raising the small-object threshold increases small-instance proportion to **39.2%**, confirming strong scale sensitivity within the dataset.

---

# ğŸ¨ Preprocessing & Augmentation (Roboflow Platform)

All preprocessing and augmentation operations were performed **offline on the Roboflow platform prior to training**.  
The augmented images were exported as part of the final fixed training dataset.

## ğŸ”¹ Preprocessing

- Auto-orient (EXIF-based correction)
- Resize to **640Ã—640**
- Adaptive histogram equalization (contrast enhancement)

These steps standardize scale, prevent rotational bias, and improve boundary visibility for small objects.

---

## ğŸ”¹ Dataset Expansion (3Ã— Augmentation)

Each training image generated **three independent augmented variants**.

Stochastic augmentations included:

- Horizontal flip  
- Rotation (âˆ’14Â° to +14Â°)  
- Shear (Â±13Â°)  
- Grayscale conversion (10% probability)  
- Gaussian blur (â‰¤1.6 px kernel)

### ğŸ” Why This Matters

Surveillance imagery often suffers from:

- Motion blur  
- Perspective distortion  
- Lighting variability  
- Camera misalignment  
- Reduced color fidelity  

The Roboflow-based augmentation pipeline increases appearance diversity while preserving label integrity.

This leads to:

- Improved small-object localization
- Greater illumination robustness
- Reduced overfitting
- Stronger generalization to unseen surveillance footage

---

# ğŸ“ˆ Performance Improvements

| Metric | Improvement |
|---|---|
| mAP@0.50 | +7.1% |
| mAP@0.50â€“0.95 | +7.0% |
| F1-score | +7.4% |

Performance gains are most pronounced for small and medium-scale luggage instances, validating the scale-aware training strategy.

---
